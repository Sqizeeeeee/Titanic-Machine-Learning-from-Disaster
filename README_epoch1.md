# Titanic Kaggle — Epoch 1

## Что было сделано

- Выбран baseline набор признаков: `Age`, `Sex`, `Pclass`
- Проведена обработка данных:
  - Пропуски в `Age` заполнены медианой
  - Пол (`Sex`) закодирован в 0/1
- Проведена нормализация признаков (`Age` и `Pclass`)
- Построена ручная логистическая регрессия (`MyModel`):
- Добавлена модель из sklearn (`SKLRWrapper`) для сравнения
- Проведен parameter tuning ручной модели:
  - Перебор по learning rate (`lr`) и числу эпох (`epochs`)

## Parameter tuning для ручной модели

| lr   | epochs | Validation accuracy |
|------|--------|-------------------|
| 0.01 | 1000   | 0.7877            |
| 0.01 | 2000   | 0.7933            |
| 0.01 | 3000   | 0.7989            |
| 0.02 | 1000   | 0.7933            |
| 0.02 | 2000   | 0.7989            |
| 0.02 | 3000   | 0.8101            |
| 0.05 | 1000   | 0.8045            |
| 0.05 | 2000   | 0.8101            |
| 0.05 | 3000   | 0.8101            |

**Лучшие параметры:** `lr=0.02`, `epochs=3000` → Validation accuracy = 0.8101

## Сравнение моделей на validation

| Модель       | Weights (w)                  | Bias (b)   | Validation accuracy |
|-------------|-------------------------------|-----------|-------------------|
| Manual Model | [-0.3351, 1.2253, -0.8761]  | -0.6795   | 0.8101            |
| SKLRWrapper  | [-0.3304, 1.2134, -0.8654]  | -0.6778   | 0.8045            |

**Вывод:** Ручная модель после tuning почти совпадает с библиотечной по параметрам и точности.

## Результаты сабмитов на Kaggle

| Модель       | Public Score |
|-------------|--------------|
| Manual Model | 0.76076      |
| SKLRWrapper  | 0.76315      |
